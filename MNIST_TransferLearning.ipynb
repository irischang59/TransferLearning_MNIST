{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Create a new FNN that reuses all the pretrained hidden layers of the previous model, freezes them, and replaces the softmax output layer with a fresh new one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the best model's graph and get a handle on all the important operations we will need. Instead of creating a new softmax output layer, we will just reuse the existing one (since it has the same number of outputs as the existing one). We will reinitialize its parameters before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iris/anaconda2/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "he_init = tf.variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "restore_saver = tf.train.import_meta_graph(\"./my_best_mnist_model_0_to_4.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "loss = tf.get_default_graph().get_tensor_by_name(\"loss:0\")\n",
    "Y_proba = tf.get_default_graph().get_tensor_by_name(\"Y_proba:0\")\n",
    "logits = Y_proba.op.inputs[0]\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"accuracy:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "five_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Train this new DNN on digits 5 to 9, using only 100 images per digit, and time how long it takes. Despite this small number of examples, can you achieve high precision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2_full = X_train[y_train >= 5]\n",
    "y_train2_full = y_train[y_train >= 5] - 5\n",
    "X_valid2_full = X_valid[y_valid >= 5]\n",
    "y_valid2_full = y_valid[y_valid >= 5] - 5\n",
    "X_test2 = X_test[y_test >= 5]\n",
    "y_test2 = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep only 100 instances per class in the training set and 30 instances per class in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, y_train2 = sample_n_instances_per_class(X_train2_full, y_train2_full, n=100)\n",
    "X_valid2, y_valid2 = sample_n_instances_per_class(X_valid2_full, y_valid2_full, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_best_mnist_model_0_to_4\n",
      "0\tValidation loss: 1.128565\tBest loss: 1.128565\tAccuracy: 52.67%\n",
      "1\tValidation loss: 1.029821\tBest loss: 1.029821\tAccuracy: 64.67%\n",
      "2\tValidation loss: 0.993459\tBest loss: 0.993459\tAccuracy: 64.00%\n",
      "3\tValidation loss: 0.888007\tBest loss: 0.888007\tAccuracy: 69.33%\n",
      "4\tValidation loss: 0.921085\tBest loss: 0.888007\tAccuracy: 66.00%\n",
      "5\tValidation loss: 0.919291\tBest loss: 0.888007\tAccuracy: 65.33%\n",
      "6\tValidation loss: 0.869334\tBest loss: 0.869334\tAccuracy: 66.67%\n",
      "7\tValidation loss: 0.875244\tBest loss: 0.869334\tAccuracy: 69.33%\n",
      "8\tValidation loss: 0.875298\tBest loss: 0.869334\tAccuracy: 65.33%\n",
      "9\tValidation loss: 0.852886\tBest loss: 0.852886\tAccuracy: 66.67%\n",
      "10\tValidation loss: 0.881996\tBest loss: 0.852886\tAccuracy: 65.33%\n",
      "11\tValidation loss: 0.889728\tBest loss: 0.852886\tAccuracy: 67.33%\n",
      "12\tValidation loss: 0.885761\tBest loss: 0.852886\tAccuracy: 66.67%\n",
      "13\tValidation loss: 0.896800\tBest loss: 0.852886\tAccuracy: 66.00%\n",
      "14\tValidation loss: 0.988275\tBest loss: 0.852886\tAccuracy: 64.00%\n",
      "15\tValidation loss: 0.872202\tBest loss: 0.852886\tAccuracy: 66.00%\n",
      "16\tValidation loss: 0.910674\tBest loss: 0.852886\tAccuracy: 68.00%\n",
      "17\tValidation loss: 0.848916\tBest loss: 0.848916\tAccuracy: 72.00%\n",
      "18\tValidation loss: 0.856171\tBest loss: 0.848916\tAccuracy: 72.00%\n",
      "19\tValidation loss: 0.836727\tBest loss: 0.836727\tAccuracy: 68.67%\n",
      "20\tValidation loss: 0.831181\tBest loss: 0.831181\tAccuracy: 70.00%\n",
      "21\tValidation loss: 0.902166\tBest loss: 0.831181\tAccuracy: 68.00%\n",
      "22\tValidation loss: 0.882459\tBest loss: 0.831181\tAccuracy: 69.33%\n",
      "23\tValidation loss: 0.869964\tBest loss: 0.831181\tAccuracy: 66.67%\n",
      "24\tValidation loss: 0.874511\tBest loss: 0.831181\tAccuracy: 69.33%\n",
      "25\tValidation loss: 0.873019\tBest loss: 0.831181\tAccuracy: 68.00%\n",
      "26\tValidation loss: 0.841874\tBest loss: 0.831181\tAccuracy: 71.33%\n",
      "27\tValidation loss: 0.859312\tBest loss: 0.831181\tAccuracy: 71.33%\n",
      "28\tValidation loss: 0.850952\tBest loss: 0.831181\tAccuracy: 69.33%\n",
      "29\tValidation loss: 0.919295\tBest loss: 0.831181\tAccuracy: 69.33%\n",
      "30\tValidation loss: 0.886726\tBest loss: 0.831181\tAccuracy: 69.33%\n",
      "31\tValidation loss: 0.889087\tBest loss: 0.831181\tAccuracy: 70.00%\n",
      "32\tValidation loss: 0.916510\tBest loss: 0.831181\tAccuracy: 67.33%\n",
      "33\tValidation loss: 0.945784\tBest loss: 0.831181\tAccuracy: 70.00%\n",
      "34\tValidation loss: 0.902390\tBest loss: 0.831181\tAccuracy: 68.00%\n",
      "35\tValidation loss: 0.843712\tBest loss: 0.831181\tAccuracy: 70.00%\n",
      "36\tValidation loss: 0.865064\tBest loss: 0.831181\tAccuracy: 70.00%\n",
      "37\tValidation loss: 0.837443\tBest loss: 0.831181\tAccuracy: 72.67%\n",
      "38\tValidation loss: 0.903202\tBest loss: 0.831181\tAccuracy: 66.67%\n",
      "39\tValidation loss: 0.957567\tBest loss: 0.831181\tAccuracy: 64.67%\n",
      "40\tValidation loss: 0.893559\tBest loss: 0.831181\tAccuracy: 69.33%\n",
      "Early stopping!\n",
      "Total training time: 2.1s\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_five_frozen\n",
      "Final test accuracy: 63.65%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_best_mnist_model_0_to_4\")\n",
    "    t0 = time.time()\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is ok, given a tiny training set and with only one layer to tweak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Try caching the frozen layers, and train the model again: how much faster is it now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden5_out = tf.get_default_graph().get_tensor_by_name(\"hidden5_out:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_best_mnist_model_0_to_4\n",
      "0\tValidation loss: 1.113713\tBest loss: 1.113713\tAccuracy: 57.33%\n",
      "1\tValidation loss: 0.986192\tBest loss: 0.986192\tAccuracy: 68.00%\n",
      "2\tValidation loss: 0.927294\tBest loss: 0.927294\tAccuracy: 69.33%\n",
      "3\tValidation loss: 0.978427\tBest loss: 0.927294\tAccuracy: 64.00%\n",
      "4\tValidation loss: 0.883225\tBest loss: 0.883225\tAccuracy: 65.33%\n",
      "5\tValidation loss: 0.868069\tBest loss: 0.868069\tAccuracy: 66.00%\n",
      "6\tValidation loss: 0.926132\tBest loss: 0.868069\tAccuracy: 66.00%\n",
      "7\tValidation loss: 0.933927\tBest loss: 0.868069\tAccuracy: 63.33%\n",
      "8\tValidation loss: 0.972674\tBest loss: 0.868069\tAccuracy: 57.33%\n",
      "9\tValidation loss: 0.953491\tBest loss: 0.868069\tAccuracy: 60.67%\n",
      "10\tValidation loss: 0.916571\tBest loss: 0.868069\tAccuracy: 66.67%\n",
      "11\tValidation loss: 0.845653\tBest loss: 0.845653\tAccuracy: 68.67%\n",
      "12\tValidation loss: 0.911072\tBest loss: 0.845653\tAccuracy: 64.00%\n",
      "13\tValidation loss: 0.893564\tBest loss: 0.845653\tAccuracy: 70.67%\n",
      "14\tValidation loss: 0.896373\tBest loss: 0.845653\tAccuracy: 64.67%\n",
      "15\tValidation loss: 0.921760\tBest loss: 0.845653\tAccuracy: 66.67%\n",
      "16\tValidation loss: 0.947816\tBest loss: 0.845653\tAccuracy: 65.33%\n",
      "17\tValidation loss: 1.025979\tBest loss: 0.845653\tAccuracy: 59.33%\n",
      "18\tValidation loss: 0.952643\tBest loss: 0.845653\tAccuracy: 70.00%\n",
      "19\tValidation loss: 0.931513\tBest loss: 0.845653\tAccuracy: 65.33%\n",
      "20\tValidation loss: 0.972332\tBest loss: 0.845653\tAccuracy: 64.00%\n",
      "21\tValidation loss: 0.877620\tBest loss: 0.845653\tAccuracy: 72.00%\n",
      "22\tValidation loss: 0.872953\tBest loss: 0.845653\tAccuracy: 67.33%\n",
      "23\tValidation loss: 0.856091\tBest loss: 0.845653\tAccuracy: 73.33%\n",
      "24\tValidation loss: 0.886580\tBest loss: 0.845653\tAccuracy: 71.33%\n",
      "25\tValidation loss: 0.856992\tBest loss: 0.845653\tAccuracy: 69.33%\n",
      "26\tValidation loss: 0.881952\tBest loss: 0.845653\tAccuracy: 69.33%\n",
      "27\tValidation loss: 0.867091\tBest loss: 0.845653\tAccuracy: 72.67%\n",
      "28\tValidation loss: 0.874344\tBest loss: 0.845653\tAccuracy: 70.67%\n",
      "29\tValidation loss: 0.858140\tBest loss: 0.845653\tAccuracy: 68.00%\n",
      "30\tValidation loss: 0.899416\tBest loss: 0.845653\tAccuracy: 68.00%\n",
      "31\tValidation loss: 0.872210\tBest loss: 0.845653\tAccuracy: 72.00%\n",
      "32\tValidation loss: 0.838508\tBest loss: 0.838508\tAccuracy: 70.67%\n",
      "33\tValidation loss: 0.858546\tBest loss: 0.838508\tAccuracy: 68.67%\n",
      "34\tValidation loss: 0.865486\tBest loss: 0.838508\tAccuracy: 67.33%\n",
      "35\tValidation loss: 0.929063\tBest loss: 0.838508\tAccuracy: 66.00%\n",
      "36\tValidation loss: 1.017279\tBest loss: 0.838508\tAccuracy: 66.00%\n",
      "37\tValidation loss: 0.920037\tBest loss: 0.838508\tAccuracy: 66.00%\n",
      "38\tValidation loss: 0.854562\tBest loss: 0.838508\tAccuracy: 74.00%\n",
      "39\tValidation loss: 0.885539\tBest loss: 0.838508\tAccuracy: 70.00%\n",
      "40\tValidation loss: 0.913932\tBest loss: 0.838508\tAccuracy: 71.33%\n",
      "41\tValidation loss: 0.891043\tBest loss: 0.838508\tAccuracy: 70.00%\n",
      "42\tValidation loss: 1.053522\tBest loss: 0.838508\tAccuracy: 60.67%\n",
      "43\tValidation loss: 0.925239\tBest loss: 0.838508\tAccuracy: 67.33%\n",
      "44\tValidation loss: 0.933265\tBest loss: 0.838508\tAccuracy: 66.00%\n",
      "45\tValidation loss: 0.846090\tBest loss: 0.838508\tAccuracy: 72.00%\n",
      "46\tValidation loss: 0.903174\tBest loss: 0.838508\tAccuracy: 66.00%\n",
      "47\tValidation loss: 0.869675\tBest loss: 0.838508\tAccuracy: 70.00%\n",
      "48\tValidation loss: 0.891254\tBest loss: 0.838508\tAccuracy: 68.67%\n",
      "49\tValidation loss: 0.899118\tBest loss: 0.838508\tAccuracy: 64.67%\n",
      "50\tValidation loss: 0.878277\tBest loss: 0.838508\tAccuracy: 72.67%\n",
      "51\tValidation loss: 0.945876\tBest loss: 0.838508\tAccuracy: 68.67%\n",
      "52\tValidation loss: 0.888272\tBest loss: 0.838508\tAccuracy: 68.67%\n",
      "Early stopping!\n",
      "Total training time: 1.6s\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_five_frozen\n",
      "Final test accuracy: 65.52%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_best_mnist_model_0_to_4\")\n",
    "    t0 = time.time()\n",
    "    \n",
    "    hidden5_train = hidden5_out.eval(feed_dict={X: X_train2, y: y_train2})\n",
    "    hidden5_valid = hidden5_out.eval(feed_dict={X: X_valid2, y: y_valid2})\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            h5_batch, y_batch = hidden5_train[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={hidden5_out: h5_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={hidden5_out: hidden5_valid, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Try again reusing just four hidden layers instead of five. Can you achieve a higher precision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_outputs = 5\n",
    "\n",
    "restore_saver = tf.train.import_meta_graph(\"./my_best_mnist_model_0_to_4.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "hidden4_out = tf.get_default_graph().get_tensor_by_name(\"hidden4_out:0\")\n",
    "logits = tf.layers.dense(hidden4_out, n_outputs, kernel_initializer=he_init, name=\"new_logits\")\n",
    "Y_proba = tf.nn.softmax(logits)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"new_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "four_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_best_mnist_model_0_to_4\n",
      "0\tValidation loss: 1.061010\tBest loss: 1.061010\tAccuracy: 60.67%\n",
      "1\tValidation loss: 0.977865\tBest loss: 0.977865\tAccuracy: 67.33%\n",
      "2\tValidation loss: 0.963718\tBest loss: 0.963718\tAccuracy: 64.67%\n",
      "3\tValidation loss: 0.866953\tBest loss: 0.866953\tAccuracy: 69.33%\n",
      "4\tValidation loss: 0.893164\tBest loss: 0.866953\tAccuracy: 66.67%\n",
      "5\tValidation loss: 0.861440\tBest loss: 0.861440\tAccuracy: 67.33%\n",
      "6\tValidation loss: 0.815578\tBest loss: 0.815578\tAccuracy: 68.67%\n",
      "7\tValidation loss: 0.822610\tBest loss: 0.815578\tAccuracy: 69.33%\n",
      "8\tValidation loss: 0.821225\tBest loss: 0.815578\tAccuracy: 69.33%\n",
      "9\tValidation loss: 0.797117\tBest loss: 0.797117\tAccuracy: 73.33%\n",
      "10\tValidation loss: 0.800130\tBest loss: 0.797117\tAccuracy: 70.00%\n",
      "11\tValidation loss: 0.811986\tBest loss: 0.797117\tAccuracy: 70.00%\n",
      "12\tValidation loss: 0.789520\tBest loss: 0.789520\tAccuracy: 72.67%\n",
      "13\tValidation loss: 0.818175\tBest loss: 0.789520\tAccuracy: 70.00%\n",
      "14\tValidation loss: 0.833462\tBest loss: 0.789520\tAccuracy: 68.00%\n",
      "15\tValidation loss: 0.769480\tBest loss: 0.769480\tAccuracy: 69.33%\n",
      "16\tValidation loss: 0.802164\tBest loss: 0.769480\tAccuracy: 69.33%\n",
      "17\tValidation loss: 0.751032\tBest loss: 0.751032\tAccuracy: 76.00%\n",
      "18\tValidation loss: 0.749630\tBest loss: 0.749630\tAccuracy: 68.67%\n",
      "19\tValidation loss: 0.752065\tBest loss: 0.749630\tAccuracy: 72.00%\n",
      "20\tValidation loss: 0.742449\tBest loss: 0.742449\tAccuracy: 70.67%\n",
      "21\tValidation loss: 0.761752\tBest loss: 0.742449\tAccuracy: 74.67%\n",
      "22\tValidation loss: 0.778844\tBest loss: 0.742449\tAccuracy: 72.67%\n",
      "23\tValidation loss: 0.744635\tBest loss: 0.742449\tAccuracy: 71.33%\n",
      "24\tValidation loss: 0.747859\tBest loss: 0.742449\tAccuracy: 70.00%\n",
      "25\tValidation loss: 0.757523\tBest loss: 0.742449\tAccuracy: 70.00%\n",
      "26\tValidation loss: 0.732000\tBest loss: 0.732000\tAccuracy: 73.33%\n",
      "27\tValidation loss: 0.761477\tBest loss: 0.732000\tAccuracy: 71.33%\n",
      "28\tValidation loss: 0.758685\tBest loss: 0.732000\tAccuracy: 74.67%\n",
      "29\tValidation loss: 0.758656\tBest loss: 0.732000\tAccuracy: 72.67%\n",
      "30\tValidation loss: 0.738239\tBest loss: 0.732000\tAccuracy: 73.33%\n",
      "31\tValidation loss: 0.740645\tBest loss: 0.732000\tAccuracy: 74.00%\n",
      "32\tValidation loss: 0.742968\tBest loss: 0.732000\tAccuracy: 74.00%\n",
      "33\tValidation loss: 0.771143\tBest loss: 0.732000\tAccuracy: 70.67%\n",
      "34\tValidation loss: 0.762722\tBest loss: 0.732000\tAccuracy: 74.00%\n",
      "35\tValidation loss: 0.748127\tBest loss: 0.732000\tAccuracy: 73.33%\n",
      "36\tValidation loss: 0.761572\tBest loss: 0.732000\tAccuracy: 73.33%\n",
      "37\tValidation loss: 0.731210\tBest loss: 0.731210\tAccuracy: 73.33%\n",
      "38\tValidation loss: 0.800342\tBest loss: 0.731210\tAccuracy: 74.67%\n",
      "39\tValidation loss: 0.778171\tBest loss: 0.731210\tAccuracy: 72.67%\n",
      "40\tValidation loss: 0.761526\tBest loss: 0.731210\tAccuracy: 72.00%\n",
      "41\tValidation loss: 0.714676\tBest loss: 0.714676\tAccuracy: 76.67%\n",
      "42\tValidation loss: 0.748432\tBest loss: 0.714676\tAccuracy: 74.00%\n",
      "43\tValidation loss: 0.764657\tBest loss: 0.714676\tAccuracy: 72.00%\n",
      "44\tValidation loss: 0.732701\tBest loss: 0.714676\tAccuracy: 74.67%\n",
      "45\tValidation loss: 0.783712\tBest loss: 0.714676\tAccuracy: 72.67%\n",
      "46\tValidation loss: 0.703283\tBest loss: 0.703283\tAccuracy: 74.67%\n",
      "47\tValidation loss: 0.699619\tBest loss: 0.699619\tAccuracy: 75.33%\n",
      "48\tValidation loss: 0.789138\tBest loss: 0.699619\tAccuracy: 73.33%\n",
      "49\tValidation loss: 0.790230\tBest loss: 0.699619\tAccuracy: 68.00%\n",
      "50\tValidation loss: 0.742658\tBest loss: 0.699619\tAccuracy: 73.33%\n",
      "51\tValidation loss: 0.762358\tBest loss: 0.699619\tAccuracy: 75.33%\n",
      "52\tValidation loss: 0.726904\tBest loss: 0.699619\tAccuracy: 72.67%\n",
      "53\tValidation loss: 0.722306\tBest loss: 0.699619\tAccuracy: 73.33%\n",
      "54\tValidation loss: 0.730039\tBest loss: 0.699619\tAccuracy: 76.67%\n",
      "55\tValidation loss: 0.787243\tBest loss: 0.699619\tAccuracy: 71.33%\n",
      "56\tValidation loss: 0.732874\tBest loss: 0.699619\tAccuracy: 73.33%\n",
      "57\tValidation loss: 0.785042\tBest loss: 0.699619\tAccuracy: 72.67%\n",
      "58\tValidation loss: 0.773259\tBest loss: 0.699619\tAccuracy: 71.33%\n",
      "59\tValidation loss: 0.782665\tBest loss: 0.699619\tAccuracy: 69.33%\n",
      "60\tValidation loss: 0.763834\tBest loss: 0.699619\tAccuracy: 73.33%\n",
      "61\tValidation loss: 0.779867\tBest loss: 0.699619\tAccuracy: 71.33%\n",
      "62\tValidation loss: 0.795061\tBest loss: 0.699619\tAccuracy: 73.33%\n",
      "63\tValidation loss: 0.731318\tBest loss: 0.699619\tAccuracy: 74.67%\n",
      "64\tValidation loss: 0.720815\tBest loss: 0.699619\tAccuracy: 77.33%\n",
      "65\tValidation loss: 0.745099\tBest loss: 0.699619\tAccuracy: 75.33%\n",
      "66\tValidation loss: 0.777950\tBest loss: 0.699619\tAccuracy: 72.00%\n",
      "67\tValidation loss: 0.735160\tBest loss: 0.699619\tAccuracy: 74.67%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_four_frozen\n",
      "Final test accuracy: 69.80%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_best_mnist_model_0_to_4\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = four_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_four_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    four_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_four_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is slightly better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Now unfreeze the top two hidden layers and continue training. Can you get the model to perform even better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "unfrozen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"hidden[34]|new_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam3\")\n",
    "training_op = optimizer.minimize(loss, var_list=unfrozen_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "two_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_four_frozen\n",
      "0\tValidation loss: 0.862952\tBest loss: 0.862952\tAccuracy: 76.67%\n",
      "1\tValidation loss: 0.833993\tBest loss: 0.833993\tAccuracy: 74.67%\n",
      "2\tValidation loss: 0.733547\tBest loss: 0.733547\tAccuracy: 78.67%\n",
      "3\tValidation loss: 0.988450\tBest loss: 0.733547\tAccuracy: 72.00%\n",
      "4\tValidation loss: 0.797596\tBest loss: 0.733547\tAccuracy: 77.33%\n",
      "5\tValidation loss: 0.967240\tBest loss: 0.733547\tAccuracy: 73.33%\n",
      "6\tValidation loss: 1.020303\tBest loss: 0.733547\tAccuracy: 75.33%\n",
      "7\tValidation loss: 0.787361\tBest loss: 0.733547\tAccuracy: 81.33%\n",
      "8\tValidation loss: 1.167076\tBest loss: 0.733547\tAccuracy: 79.33%\n",
      "9\tValidation loss: 1.340540\tBest loss: 0.733547\tAccuracy: 79.33%\n",
      "10\tValidation loss: 1.255924\tBest loss: 0.733547\tAccuracy: 80.67%\n",
      "11\tValidation loss: 1.598556\tBest loss: 0.733547\tAccuracy: 77.33%\n",
      "12\tValidation loss: 1.169137\tBest loss: 0.733547\tAccuracy: 79.33%\n",
      "13\tValidation loss: 1.180845\tBest loss: 0.733547\tAccuracy: 78.00%\n",
      "14\tValidation loss: 0.998261\tBest loss: 0.733547\tAccuracy: 78.67%\n",
      "15\tValidation loss: 1.253458\tBest loss: 0.733547\tAccuracy: 78.67%\n",
      "16\tValidation loss: 1.147943\tBest loss: 0.733547\tAccuracy: 79.33%\n",
      "17\tValidation loss: 1.144818\tBest loss: 0.733547\tAccuracy: 77.33%\n",
      "18\tValidation loss: 1.133051\tBest loss: 0.733547\tAccuracy: 80.00%\n",
      "19\tValidation loss: 1.202824\tBest loss: 0.733547\tAccuracy: 81.33%\n",
      "20\tValidation loss: 1.201501\tBest loss: 0.733547\tAccuracy: 82.00%\n",
      "21\tValidation loss: 1.272700\tBest loss: 0.733547\tAccuracy: 81.33%\n",
      "22\tValidation loss: 1.341889\tBest loss: 0.733547\tAccuracy: 80.67%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_two_frozen\n",
      "Final test accuracy: 77.64%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    four_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_four_frozen\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = two_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_two_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    two_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_two_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam4\")\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "no_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_two_frozen\n",
      "0\tValidation loss: 0.523072\tBest loss: 0.523072\tAccuracy: 86.00%\n",
      "1\tValidation loss: 0.352548\tBest loss: 0.352548\tAccuracy: 89.33%\n",
      "2\tValidation loss: 0.320126\tBest loss: 0.320126\tAccuracy: 91.33%\n",
      "3\tValidation loss: 0.624296\tBest loss: 0.320126\tAccuracy: 86.67%\n",
      "4\tValidation loss: 0.331089\tBest loss: 0.320126\tAccuracy: 93.33%\n",
      "5\tValidation loss: 0.558394\tBest loss: 0.320126\tAccuracy: 90.00%\n",
      "6\tValidation loss: 0.530679\tBest loss: 0.320126\tAccuracy: 92.67%\n",
      "7\tValidation loss: 0.703869\tBest loss: 0.320126\tAccuracy: 92.00%\n",
      "8\tValidation loss: 0.687185\tBest loss: 0.320126\tAccuracy: 90.00%\n",
      "9\tValidation loss: 0.744075\tBest loss: 0.320126\tAccuracy: 90.67%\n",
      "10\tValidation loss: 0.496201\tBest loss: 0.320126\tAccuracy: 91.33%\n",
      "11\tValidation loss: 0.477802\tBest loss: 0.320126\tAccuracy: 91.33%\n",
      "12\tValidation loss: 0.632141\tBest loss: 0.320126\tAccuracy: 89.33%\n",
      "13\tValidation loss: 0.494414\tBest loss: 0.320126\tAccuracy: 94.67%\n",
      "14\tValidation loss: 0.687644\tBest loss: 0.320126\tAccuracy: 88.67%\n",
      "15\tValidation loss: 0.705526\tBest loss: 0.320126\tAccuracy: 89.33%\n",
      "16\tValidation loss: 0.746004\tBest loss: 0.320126\tAccuracy: 88.00%\n",
      "17\tValidation loss: 0.549984\tBest loss: 0.320126\tAccuracy: 92.00%\n",
      "18\tValidation loss: 0.674594\tBest loss: 0.320126\tAccuracy: 94.67%\n",
      "19\tValidation loss: 0.693043\tBest loss: 0.320126\tAccuracy: 92.67%\n",
      "20\tValidation loss: 0.581194\tBest loss: 0.320126\tAccuracy: 94.00%\n",
      "21\tValidation loss: 0.654243\tBest loss: 0.320126\tAccuracy: 91.33%\n",
      "22\tValidation loss: 0.664140\tBest loss: 0.320126\tAccuracy: 91.33%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_no_frozen\n",
      "Final test accuracy: 87.31%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    two_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_two_frozen\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = no_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_no_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    no_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_no_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, transfer learning did not work well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
